{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Is eager execution enabled?: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from dataset import load_dataset_from_tfrecord\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Is eager execution enabled?:\", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t2w': <tf.Tensor: shape=(256, 256, 1), dtype=float32, numpy=\n",
      "array([[[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]], dtype=float32)>, 't1w': <tf.Tensor: shape=(256, 256, 1), dtype=float32, numpy=\n",
      "array([[[0.00784314],\n",
      "        [0.00784314],\n",
      "        [0.00784314],\n",
      "        ...,\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.00784314],\n",
      "        [0.00784314],\n",
      "        [0.00784314],\n",
      "        ...,\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.00784314],\n",
      "        [0.00784314],\n",
      "        [0.00784314],\n",
      "        ...,\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        ...,\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        ...,\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        ...,\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]]], dtype=float32)>, 'patient_id': <tf.Tensor: shape=(), dtype=string, numpy=b'sub-amu01'>}\n",
      "(256, 256, 1)\n",
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "modalities = ['t2w', 't1w']\n",
    "loaded_dataset = load_dataset_from_tfrecord(os.path.join('datasets', '_'.join(modalities) + '_dataset.tfrecord'), modalities)\n",
    "\n",
    "# Print an example of the dataset\n",
    "for example in loaded_dataset.take(1):\n",
    "    print(example)\n",
    "    print(example['t2w'].shape)\n",
    "    print(example['t1w'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):\n",
    "    print(f\"{name}: Input shape:\", x.shape)\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same', name=name+'_shortcut')(shortcut)\n",
    "        shortcut = layers.BatchNormalization(name=name+'_shortcut_bn')(shortcut)\n",
    "        print(f\"{name}: Shortcut shape after conv:\", shortcut.shape)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', name=name+'_conv1')(x)\n",
    "    x = layers.BatchNormalization(name=name+'_bn1')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    print(f\"{name}: Shape after first conv:\", x.shape)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', name=name+'_conv2')(x)\n",
    "    x = layers.BatchNormalization(name=name+'_bn2')(x)\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    print(f\"{name}: Output shape:\", x.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_model():\n",
    "    input1 = layers.Input(shape=(256, 256, 1), name='image1')\n",
    "    input2 = layers.Input(shape=(256, 256, 1), name='image2')\n",
    "\n",
    "    print(\"Input1 shape:\", input1.shape)\n",
    "    print(\"Input2 shape:\", input2.shape)\n",
    "\n",
    "    conv1_branch1 = layers.Conv2D(32, 3, strides=1, padding='same', name='conv1_branch1')(input1)\n",
    "    conv1_branch2 = layers.Conv2D(32, 3, strides=1, padding='same', name='conv1_branch2')(input2)\n",
    "\n",
    "    print(\"conv1_branch1 shape:\", conv1_branch1.shape)\n",
    "    print(\"conv1_branch2 shape:\", conv1_branch2.shape)\n",
    "\n",
    "    res_block_branch1 = residual_block(conv1_branch1, 32, name='res_block_branch1')\n",
    "    res_block_branch2 = residual_block(conv1_branch2, 32, name='res_block_branch2')\n",
    "\n",
    "    concatenated_features = layers.Concatenate(axis=-1)([res_block_branch1, res_block_branch2])\n",
    "    print(\"Concatenated features shape:\", concatenated_features.shape)\n",
    "\n",
    "    res_block_concat = residual_block(concatenated_features, 64, name='res_block_concat')\n",
    "\n",
    "    conv2 = layers.Conv2D(32, 3, strides=1, padding='same', name='conv2')(res_block_concat)\n",
    "    conv3 = layers.Conv2D(1, 3, strides=1, padding='same', name='conv3')(conv2)\n",
    "\n",
    "    sigmoid_output = layers.Activation('sigmoid')(conv3)\n",
    "    weighted_avg_output = layers.Average()([sigmoid_output, input1, input2])\n",
    "\n",
    "    print(\"Final output shape:\", weighted_avg_output.shape)\n",
    "\n",
    "    model = models.Model(inputs=[input1, input2], outputs=weighted_avg_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input1 shape: (None, 256, 256, 1)\n",
      "Input2 shape: (None, 256, 256, 1)\n",
      "conv1_branch1 shape: (None, 256, 256, 32)\n",
      "conv1_branch2 shape: (None, 256, 256, 32)\n",
      "res_block_branch1: Input shape: (None, 256, 256, 32)\n",
      "res_block_branch1: Shape after first conv: (None, 256, 256, 32)\n",
      "res_block_branch1: Output shape: (None, 256, 256, 32)\n",
      "res_block_branch2: Input shape: (None, 256, 256, 32)\n",
      "res_block_branch2: Shape after first conv: (None, 256, 256, 32)\n",
      "res_block_branch2: Output shape: (None, 256, 256, 32)\n",
      "Concatenated features shape: (None, 256, 256, 64)\n",
      "res_block_concat: Input shape: (None, 256, 256, 64)\n",
      "res_block_concat: Shape after first conv: (None, 256, 256, 64)\n",
      "res_block_concat: Output shape: (None, 256, 256, 64)\n",
      "Final output shape: (None, 256, 256, 1)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image1 (InputLayer)         [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " image2 (InputLayer)         [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_branch1 (Conv2D)      (None, 256, 256, 32)         320       ['image1[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_branch2 (Conv2D)      (None, 256, 256, 32)         320       ['image2[0][0]']              \n",
      "                                                                                                  \n",
      " res_block_branch1_conv1 (C  (None, 256, 256, 32)         9248      ['conv1_branch1[0][0]']       \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " res_block_branch2_conv1 (C  (None, 256, 256, 32)         9248      ['conv1_branch2[0][0]']       \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " res_block_branch1_bn1 (Bat  (None, 256, 256, 32)         128       ['res_block_branch1_conv1[0][0\n",
      " chNormalization)                                                   ]']                           \n",
      "                                                                                                  \n",
      " res_block_branch2_bn1 (Bat  (None, 256, 256, 32)         128       ['res_block_branch2_conv1[0][0\n",
      " chNormalization)                                                   ]']                           \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)             (None, 256, 256, 32)         0         ['res_block_branch1_bn1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)             (None, 256, 256, 32)         0         ['res_block_branch2_bn1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " res_block_branch1_conv2 (C  (None, 256, 256, 32)         9248      ['re_lu_24[0][0]']            \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " res_block_branch2_conv2 (C  (None, 256, 256, 32)         9248      ['re_lu_26[0][0]']            \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " res_block_branch1_bn2 (Bat  (None, 256, 256, 32)         128       ['res_block_branch1_conv2[0][0\n",
      " chNormalization)                                                   ]']                           \n",
      "                                                                                                  \n",
      " res_block_branch2_bn2 (Bat  (None, 256, 256, 32)         128       ['res_block_branch2_conv2[0][0\n",
      " chNormalization)                                                   ]']                           \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 256, 256, 32)         0         ['res_block_branch1_bn2[0][0]'\n",
      "                                                                    , 'conv1_branch1[0][0]']      \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 256, 256, 32)         0         ['res_block_branch2_bn2[0][0]'\n",
      "                                                                    , 'conv1_branch2[0][0]']      \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)             (None, 256, 256, 32)         0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)             (None, 256, 256, 32)         0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 256, 256, 64)         0         ['re_lu_25[0][0]',            \n",
      " )                                                                   're_lu_27[0][0]']            \n",
      "                                                                                                  \n",
      " res_block_concat_conv1 (Co  (None, 256, 256, 64)         36928     ['concatenate_4[0][0]']       \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " res_block_concat_bn1 (Batc  (None, 256, 256, 64)         256       ['res_block_concat_conv1[0][0]\n",
      " hNormalization)                                                    ']                            \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)             (None, 256, 256, 64)         0         ['res_block_concat_bn1[0][0]']\n",
      "                                                                                                  \n",
      " res_block_concat_conv2 (Co  (None, 256, 256, 64)         36928     ['re_lu_28[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " res_block_concat_bn2 (Batc  (None, 256, 256, 64)         256       ['res_block_concat_conv2[0][0]\n",
      " hNormalization)                                                    ']                            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 256, 256, 64)         0         ['res_block_concat_bn2[0][0]',\n",
      "                                                                     'concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)             (None, 256, 256, 64)         0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)              (None, 256, 256, 32)         18464     ['re_lu_29[0][0]']            \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)              (None, 256, 256, 1)          289       ['conv2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 256, 256, 1)          0         ['conv3[0][0]']               \n",
      "                                                                                                  \n",
      " average_4 (Average)         (None, 256, 256, 1)          0         ['activation_4[0][0]',        \n",
      "                                                                     'image1[0][0]',              \n",
      "                                                                     'image2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131265 (512.75 KB)\n",
      "Trainable params: 130753 (510.75 KB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "image1 [(None, 256, 256, 1)]\n",
      "image2 [(None, 256, 256, 1)]\n",
      "conv1_branch1 (None, 256, 256, 32)\n",
      "conv1_branch2 (None, 256, 256, 32)\n",
      "res_block_branch1_conv1 (None, 256, 256, 32)\n",
      "res_block_branch2_conv1 (None, 256, 256, 32)\n",
      "res_block_branch1_bn1 (None, 256, 256, 32)\n",
      "res_block_branch2_bn1 (None, 256, 256, 32)\n",
      "re_lu_24 (None, 256, 256, 32)\n",
      "re_lu_26 (None, 256, 256, 32)\n",
      "res_block_branch1_conv2 (None, 256, 256, 32)\n",
      "res_block_branch2_conv2 (None, 256, 256, 32)\n",
      "res_block_branch1_bn2 (None, 256, 256, 32)\n",
      "res_block_branch2_bn2 (None, 256, 256, 32)\n",
      "add_12 (None, 256, 256, 32)\n",
      "add_13 (None, 256, 256, 32)\n",
      "re_lu_25 (None, 256, 256, 32)\n",
      "re_lu_27 (None, 256, 256, 32)\n",
      "concatenate_4 (None, 256, 256, 64)\n",
      "res_block_concat_conv1 (None, 256, 256, 64)\n",
      "res_block_concat_bn1 (None, 256, 256, 64)\n",
      "re_lu_28 (None, 256, 256, 64)\n",
      "res_block_concat_conv2 (None, 256, 256, 64)\n",
      "res_block_concat_bn2 (None, 256, 256, 64)\n",
      "add_14 (None, 256, 256, 64)\n",
      "re_lu_29 (None, 256, 256, 64)\n",
      "conv2 (None, 256, 256, 32)\n",
      "conv3 (None, 256, 256, 1)\n",
      "activation_4 (None, 256, 256, 1)\n",
      "average_4 (None, 256, 256, 1)\n",
      "(256, 256, 1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_25064\\3257955466.py\", line 20, in train_step  *\n        loss = ssim_loss(image1, output)  # Ensure this is compatible with eager execution\n    File \"c:\\Users\\bianc\\OneDrive\\Documents\\MTI830\\multimodal-fusion\\loss_functions.py\", line 7, in ssim_loss  *\n        return 1.0 - tf.reduce_mean(tf.image.ssim(true, pred, max_val))\n\n    ValueError: Shapes (256, 256, 1) and (256, 1, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m loaded_dataset:\n\u001b[0;32m     27\u001b[0m     image1, image2 \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt2w\u001b[39m\u001b[38;5;124m'\u001b[39m], example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt1w\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 28\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bianc\\anaconda3\\mti805\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filerey30mbh.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(image1, image2, model, optimizer)\u001b[0m\n\u001b[0;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model), ([ag__\u001b[38;5;241m.\u001b[39mld(image1), ag__\u001b[38;5;241m.\u001b[39mld(image2)],), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m     12\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(ag__\u001b[38;5;241m.\u001b[39mld(output)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(ssim_loss), (ag__\u001b[38;5;241m.\u001b[39mld(image1), ag__\u001b[38;5;241m.\u001b[39mld(output)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     14\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     15\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(optimizer)\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filex2bpvh0w.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__ssim_loss\u001b[1;34m(true, pred, max_val)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mssim, (ag__\u001b[38;5;241m.\u001b[39mld(true), ag__\u001b[38;5;241m.\u001b[39mld(pred), ag__\u001b[38;5;241m.\u001b[39mld(max_val)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_25064\\3257955466.py\", line 20, in train_step  *\n        loss = ssim_loss(image1, output)  # Ensure this is compatible with eager execution\n    File \"c:\\Users\\bianc\\OneDrive\\Documents\\MTI830\\multimodal-fusion\\loss_functions.py\", line 7, in ssim_loss  *\n        return 1.0 - tf.reduce_mean(tf.image.ssim(true, pred, max_val))\n\n    ValueError: Shapes (256, 256, 1) and (256, 1, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from loss_functions import ssim_loss\n",
    "\n",
    "model = build_model()\n",
    "# Print the model summary to understand the architecture\n",
    "model.summary()\n",
    "\n",
    "# For inspecting the shape of a specific layer's output:\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.output_shape)\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "@tf.function\n",
    "def train_step(image1, image2, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model([image1, image2], training=True)\n",
    "        # Print the shape of the output to ensure it is compatible with the loss function\n",
    "        print(output.shape)\n",
    "        # Visualize the output\n",
    "        loss = ssim_loss(image1, output)  # Ensure this is compatible with eager execution\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "for epoch in range(10):\n",
    "    for example in loaded_dataset:\n",
    "        image1, image2 = example['t2w'], example['t1w']\n",
    "        loss_val = train_step(image1, image2, model, optimizer)\n",
    "        print(f'Loss: {loss_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model_tf2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mti805",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

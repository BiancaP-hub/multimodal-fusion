{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Is eager execution enabled?: True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from dataset import load_dataset_from_tfrecord\n",
    "import os\n",
    "from io import StringIO\n",
    "import wandb\n",
    "from loss_functions import ssim_loss\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Is eager execution enabled?:\", tf.executing_eagerly())\n",
    "# Check if GPU is available\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t2w': <tf.Tensor: shape=(16, 256, 256, 1), dtype=float32, numpy=\n",
      "array([[[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00392157],\n",
      "         [0.        ],\n",
      "         [0.00392157]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00392157],\n",
      "         [0.00392157],\n",
      "         [0.00392157]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00392157]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00392157],\n",
      "         [0.00784314],\n",
      "         [0.00392157]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00392157],\n",
      "         [0.00392157],\n",
      "         [0.00392157]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00392157],\n",
      "         [0.00392157],\n",
      "         [0.00392157]]],\n",
      "\n",
      "\n",
      "       [[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.1882353 ],\n",
      "         [0.25882354],\n",
      "         [0.23529412],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00392157],\n",
      "         [0.00392157],\n",
      "         [0.00392157]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.00392157],\n",
      "         [0.00392157],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]]], dtype=float32)>, 't1w': <tf.Tensor: shape=(16, 256, 256, 1), dtype=float32, numpy=\n",
      "array([[[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.00392157],\n",
      "         [0.00392157],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.00784314],\n",
      "         [0.00392157],\n",
      "         [0.00784314],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.01176471],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.2       ],\n",
      "         [0.09411765],\n",
      "         [0.2       ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.12941177],\n",
      "         [0.14509805],\n",
      "         [0.24705882],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.09803922],\n",
      "         [0.19607843],\n",
      "         [0.24313726],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.20392157],\n",
      "         [0.25882354],\n",
      "         [0.34509805],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.22745098],\n",
      "         [0.30588236],\n",
      "         [0.38039216],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.2       ],\n",
      "         [0.30588236],\n",
      "         [0.33333334],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.03137255],\n",
      "         [0.03529412],\n",
      "         [0.03529412],\n",
      "         ...,\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314]],\n",
      "\n",
      "        [[0.03137255],\n",
      "         [0.03137255],\n",
      "         [0.03137255],\n",
      "         ...,\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314]],\n",
      "\n",
      "        [[0.03529412],\n",
      "         [0.02745098],\n",
      "         [0.03137255],\n",
      "         ...,\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         ...,\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314]],\n",
      "\n",
      "        [[0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         ...,\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314]],\n",
      "\n",
      "        [[0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         ...,\n",
      "         [0.00784314],\n",
      "         [0.00784314],\n",
      "         [0.00784314]]]], dtype=float32)>, 'patient_id': <tf.Tensor: shape=(16,), dtype=string, numpy=\n",
      "array([b'sub-cmrrb06', b'sub-oxfordFmrib01', b'sub-mniS07', b'sub-mgh03',\n",
      "       b'sub-brnoCeitec02', b'sub-brnoCeitec03', b'sub-mniS06',\n",
      "       b'sub-cmrra03', b'sub-cmrrb05', b'sub-cardiff01', b'sub-geneva05',\n",
      "       b'sub-geneva04', b'sub-juntendo750w03', b'sub-brnoUhb03',\n",
      "       b'sub-mpicbs05', b'sub-beijingGE03'], dtype=object)>}\n",
      "(16, 256, 256, 1)\n",
      "(16, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "modalities = ['t2w', 't1w']\n",
    "loaded_dataset = load_dataset_from_tfrecord(os.path.join('datasets', '_'.join(modalities) + '_dataset.tfrecord'), modalities)\n",
    "\n",
    "# # Print an example of the dataset\n",
    "# for example in loaded_dataset.take(1):\n",
    "#     print(example)\n",
    "#     print(example['t2w'].shape)\n",
    "#     print(example['t1w'].shape)\n",
    "\n",
    "DATASET_SIZE = sum(1 for _ in loaded_dataset)\n",
    "TRAIN_SIZE = int(0.8 * DATASET_SIZE)\n",
    "VAL_SIZE = int(0.1 * DATASET_SIZE)\n",
    "TEST_SIZE = DATASET_SIZE - TRAIN_SIZE - VAL_SIZE\n",
    "\n",
    "# Shuffle the dataset\n",
    "full_dataset = loaded_dataset.shuffle(buffer_size=DATASET_SIZE)\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset = full_dataset.take(TRAIN_SIZE)\n",
    "test_val_dataset = full_dataset.skip(TRAIN_SIZE)\n",
    "val_dataset = test_val_dataset.take(VAL_SIZE)\n",
    "test_dataset = test_val_dataset.skip(VAL_SIZE)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# # Print an example of the dataset\n",
    "for example in train_dataset.take(1):\n",
    "    print(example)\n",
    "    print(example['t2w'].shape)\n",
    "    print(example['t1w'].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same', name=name+'_shortcut')(shortcut)\n",
    "        shortcut = layers.BatchNormalization(name=name+'_shortcut_bn')(shortcut)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', name=name+'_conv1')(x)\n",
    "    x = layers.BatchNormalization(name=name+'_bn1')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', name=name+'_conv2')(x)\n",
    "    x = layers.BatchNormalization(name=name+'_bn2')(x)\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_model():\n",
    "    input1 = layers.Input(shape=(256, 256, 1), name='image1')\n",
    "    input2 = layers.Input(shape=(256, 256, 1), name='image2')\n",
    "\n",
    "    conv1_branch1 = layers.Conv2D(32, 3, strides=1, padding='same', name='conv1_branch1')(input1)\n",
    "    conv1_branch2 = layers.Conv2D(32, 3, strides=1, padding='same', name='conv1_branch2')(input2)\n",
    "\n",
    "    res_block_branch1 = residual_block(conv1_branch1, 32, name='res_block_branch1')\n",
    "    res_block_branch2 = residual_block(conv1_branch2, 32, name='res_block_branch2')\n",
    "\n",
    "    concatenated_features = layers.Concatenate(axis=-1)([res_block_branch1, res_block_branch2])\n",
    "\n",
    "    res_block_concat = residual_block(concatenated_features, 64, name='res_block_concat')\n",
    "\n",
    "    conv2 = layers.Conv2D(32, 3, strides=1, padding='same', name='conv2')(res_block_concat)\n",
    "    conv3 = layers.Conv2D(1, 3, strides=1, padding='same', name='conv3')(conv2)\n",
    "\n",
    "    sigmoid_output = layers.Activation('sigmoid')(conv3)\n",
    "    weighted_avg_output = layers.Average()([sigmoid_output, input1, input2])\n",
    "\n",
    "    model = models.Model(inputs=[input1, input2], outputs=weighted_avg_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbiancapopa\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\bianc\\Documents\\GitHub\\multimodal-fusion\\wandb\\run-20240206_205418-jrti0zz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/biancapopa/multicontrast-fusion/runs/jrti0zz7' target=\"_blank\">toasty-serenity-4</a></strong> to <a href='https://wandb.ai/biancapopa/multicontrast-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/biancapopa/multicontrast-fusion' target=\"_blank\">https://wandb.ai/biancapopa/multicontrast-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/biancapopa/multicontrast-fusion/runs/jrti0zz7' target=\"_blank\">https://wandb.ai/biancapopa/multicontrast-fusion/runs/jrti0zz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.16674286127090454, Validation Loss: 0.5515544414520264\n",
      "Epoch 2, Training Loss: 0.07340817153453827, Validation Loss: 0.3902691900730133\n",
      "Epoch 3, Training Loss: 0.06867815554141998, Validation Loss: 0.26098522543907166\n",
      "Epoch 4, Training Loss: 0.06618999689817429, Validation Loss: 0.1123589351773262\n",
      "Epoch 5, Training Loss: 0.06515512615442276, Validation Loss: 0.08200741559267044\n",
      "Epoch 6, Training Loss: 0.06484142690896988, Validation Loss: 0.06986849755048752\n",
      "Epoch 7, Training Loss: 0.06309933960437775, Validation Loss: 0.06415687501430511\n",
      "Epoch 8, Training Loss: 0.06459016352891922, Validation Loss: 0.06547229737043381\n",
      "Epoch 9, Training Loss: 0.06260616332292557, Validation Loss: 0.05921964347362518\n",
      "Epoch 10, Training Loss: 0.0625261440873146, Validation Loss: 0.062143683433532715\n"
     ]
    }
   ],
   "source": [
    "# Initialize Weights and Biases\n",
    "wandb.init(project='multicontrast-fusion', entity='biancapopa')\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# Capture the model summary\n",
    "str_buffer = StringIO()\n",
    "model.summary(print_fn=lambda x: str_buffer.write(x + '\\n'))\n",
    "model_summary = str_buffer.getvalue()\n",
    "\n",
    "with open(\"model_summary.txt\", \"w\") as f:\n",
    "    f.write(model_summary)\n",
    "wandb.save(\"model_summary.txt\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "max_epochs = 100\n",
    "\n",
    "# Log hyperparameters\n",
    "wandb.config.optimizer = 'Adam'\n",
    "wandb.config.learning_rate = learning_rate\n",
    "wandb.config.epochs = max_epochs\n",
    "\n",
    "# Initialize metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "# Initialize early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "wait = 0\n",
    "\n",
    "@tf.function\n",
    "def train_step(image1, image2, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model([image1, image2], training=True)\n",
    "        loss = ssim_loss(image1, output) \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    \n",
    "    for images in train_dataset:\n",
    "        image1, image2 = images['t2w'], images['t1w']\n",
    "        loss_val = train_step(image1, image2, model, optimizer)\n",
    "        train_loss.update_state(loss_val)\n",
    "    \n",
    "    for images in val_dataset:\n",
    "        image1, image2 = images['t2w'], images['t1w']\n",
    "        val_output = model([image1, image2], training=False)\n",
    "        current_val_loss = ssim_loss(image1, val_output)\n",
    "        val_loss.update_state(current_val_loss)\n",
    "\n",
    "    # Log losses to Weights and Biases\n",
    "    wandb.log({'epoch': epoch + 1, 'train_loss': train_loss.result().numpy(), 'val_loss': val_loss.result().numpy()})\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {train_loss.result()}, Validation Loss: {val_loss.result()}\")\n",
    "\n",
    "    if val_loss.result() < best_val_loss:\n",
    "        best_val_loss = val_loss.result()\n",
    "        wait = 0\n",
    "        # Log the best model\n",
    "        wandb.log({'best_val_loss': best_val_loss.numpy()})\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping due to no improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "model.save(\"model_name.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mti805",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
